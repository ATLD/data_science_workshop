{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full NLP and ML Pipeline for Document Classification\n",
    "Based on following tutorials   \n",
    "With Permission from Michale Harmon:\n",
    "http://michael-harmon.com/blog/NLP.html   \n",
    "https://github.com/mdh266/DocumentClassificationNLP/blob/master/NLP.ipynb   \n",
    "\n",
    "Classification of text documents using sparse features:   \n",
    "https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html   \n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  20 News Groups Corpus, Sample dataset included in scikit-learn\n",
    "A collection of almost 20,000 articles on 20 different topics or 'newsgroups'.   \n",
    "Corpus: Text Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 3 classes (of 20)\n",
    "twenty_train.target_names[0:3]\n",
    "# python indexing excludes end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "# data and target\n",
    "# has the input and desired output\n",
    "# 11K of them are split for training pairs\n",
    "\n",
    "print( len(twenty_train.data) )\n",
    "print( len(twenty_train.target) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jimf@centerline.com (Jim Frost)\n",
      "Subject: Re: Is car saftey important?\n",
      "Organization: CenterLine Software, Inc.\n",
      "Lines: 14\n",
      "NNTP-Posting-Host: 140.239.3.202\n",
      "\n",
      "tcorkum@bnr.ca (Trevor Corkum) writes:\n",
      ">Is it only me, or is\n",
      ">safety not one of the most important factors when buying a car?\n",
      "\n",
      "It depends on your priorities.  A lot of people put higher priorities\n",
      "on gas mileage and cost than on safety, buying \"unsafe\" econoboxes\n",
      "instead of Volvos.  I personally take a middle ground -- the only\n",
      "thing I really look for is a three-point seatbelt and 5+mph bumpers.\n",
      "I figure that 30mph collisions into brick walls aren't common enough\n",
      "for me to spend that much extra money for protection, but there are\n",
      "lots of low-speed collisions that do worry me.\n",
      "\n",
      "jim frost\n",
      "jimf@centerline.com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 29\n",
    "print(twenty_train.data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[  twenty_train.target[i]  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn Pipeline\n",
    "- Scitkit-learn pipelines are a sequence of transforms followed by a final estimator.   \n",
    "- Intermediate steps within the pipeline must be ‘transforms’ \n",
    " * they must implement fit and transform methods \n",
    " * The CountVectorizer and TfidfTransformer are transformers in this example   \n",
    "- The estimator of a pipeline, the final step, only needs to implement the fit method   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.69      0.74       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.79      0.72      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.68      0.81      0.74       392\n",
      "   comp.sys.mac.hardware       0.86      0.81      0.84       385\n",
      "          comp.windows.x       0.87      0.78      0.82       395\n",
      "            misc.forsale       0.87      0.80      0.83       390\n",
      "               rec.autos       0.88      0.91      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.91      0.92      0.92       397\n",
      "        rec.sport.hockey       0.88      0.98      0.93       399\n",
      "               sci.crypt       0.75      0.96      0.84       396\n",
      "         sci.electronics       0.84      0.65      0.74       393\n",
      "                 sci.med       0.92      0.79      0.85       396\n",
      "               sci.space       0.82      0.94      0.88       394\n",
      "  soc.religion.christian       0.62      0.96      0.76       398\n",
      "      talk.politics.guns       0.66      0.95      0.78       364\n",
      "   talk.politics.mideast       0.95      0.94      0.94       376\n",
      "      talk.politics.misc       0.94      0.52      0.67       310\n",
      "      talk.religion.misc       0.95      0.24      0.38       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.84      0.80      0.80      7532\n",
      "            weighted avg       0.83      0.82      0.81      7532\n",
      "\n",
      "Accuracy: 0.8169144981412639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('model', MultinomialNB()),])\n",
    "\n",
    "mod = pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted = mod.predict(twenty_test.data)\n",
    "\n",
    "print(classification_report(twenty_test.target,\n",
    "                            predicted, \n",
    "                            target_names=twenty_test.target_names))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.81      0.80       319\n",
      "           comp.graphics       0.65      0.80      0.72       389\n",
      " comp.os.ms-windows.misc       0.80      0.04      0.08       394\n",
      "comp.sys.ibm.pc.hardware       0.55      0.80      0.65       392\n",
      "   comp.sys.mac.hardware       0.85      0.79      0.82       385\n",
      "          comp.windows.x       0.69      0.84      0.76       395\n",
      "            misc.forsale       0.89      0.74      0.81       390\n",
      "               rec.autos       0.89      0.92      0.91       396\n",
      "         rec.motorcycles       0.95      0.94      0.95       398\n",
      "      rec.sport.baseball       0.95      0.92      0.93       397\n",
      "        rec.sport.hockey       0.92      0.97      0.94       399\n",
      "               sci.crypt       0.80      0.96      0.87       396\n",
      "         sci.electronics       0.79      0.70      0.74       393\n",
      "                 sci.med       0.88      0.87      0.87       396\n",
      "               sci.space       0.84      0.92      0.88       394\n",
      "  soc.religion.christian       0.81      0.95      0.87       398\n",
      "      talk.politics.guns       0.72      0.93      0.81       364\n",
      "   talk.politics.mideast       0.93      0.94      0.94       376\n",
      "      talk.politics.misc       0.68      0.62      0.65       310\n",
      "      talk.religion.misc       0.88      0.44      0.59       251\n",
      "\n",
      "                accuracy                           0.80      7532\n",
      "               macro avg       0.81      0.79      0.78      7532\n",
      "            weighted avg       0.81      0.80      0.78      7532\n",
      "\n",
      "Accuracy: 0.8023101433882103\n"
     ]
    }
   ],
   "source": [
    "# So easy to add, remove, or modify steps and retest \n",
    "pipe = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                  #('tfidf', TfidfTransformer()),\n",
    "                  ('model', MultinomialNB()),])\n",
    "\n",
    "mod = pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted = mod.predict(twenty_test.data)\n",
    "\n",
    "print(classification_report(twenty_test.target,\n",
    "                            predicted, \n",
    "                            target_names=twenty_test.target_names))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY: remove stop_words removal and see change in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting, and Hyperparameter tuning using GridSearchCV and Pipeline\n",
    "Similar to testing whether to remove stopwords or not, we want to run many experiments, with many combinations of parameters.  \n",
    "GridSearchCV does this, for an estimator, or on a full pipeline. \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html   \n",
    "   \n",
    "For  setting parameters of the various steps in the \n",
    "pipeline, you use <step name>+\"__\"+<parameter name>, for the list of possible values you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiments\n",
    "    \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__stop_words': ('english', None)}\n",
    "\n",
    "# We can perform the grid search using all available CPU by setting n_jobs=-1:\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiments \n",
    "gs_model = grid_search.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.31530085, 4.42989559]),\n",
       " 'std_fit_time': array([0.1378511 , 0.07756394]),\n",
       " 'mean_score_time': array([0.87700033, 0.66064115]),\n",
       " 'std_score_time': array([0.0977623, 0.0908348]),\n",
       " 'param_vect__stop_words': masked_array(data=['english', None],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'vect__stop_words': 'english'}, {'vect__stop_words': None}],\n",
       " 'split0_test_score': array([0.86866461, 0.84045835]),\n",
       " 'split1_test_score': array([0.86981465, 0.84112974]),\n",
       " 'split2_test_score': array([0.85468198, 0.82773852]),\n",
       " 'split3_test_score': array([0.8619469 , 0.83362832]),\n",
       " 'split4_test_score': array([0.86784922, 0.83991131]),\n",
       " 'mean_test_score': array([0.86459254, 0.83657416]),\n",
       " 'std_test_score': array([0.00565275, 0.00517274]),\n",
       " 'rank_test_score': array([1, 2], dtype=int32)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of \n",
    "gs_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'tfidf__use_idf': (True, False),\n",
    "              'model__alpha': (1e1, 1e-3),\n",
    "              'model__fit_prior': (True,False)}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
